{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BachProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuOabn/UIZQjYf3DtqovcO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drozzel/Portfolio/blob/main/BachProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHJCT9a-vhKg"
      },
      "source": [
        "# Bach Project\n",
        "## Notebook Summary\n",
        "###1.Import Necessary Libraries\n",
        "###2.Read In the Data Files\n",
        "###3.Clean and Organize the Data\n",
        "###4.Build and Evaluate Basic Model\n",
        "###5.Find the Ideal Parameters\n",
        "###6.Build and Evaluate Ideal Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpsPKrVfwNq8"
      },
      "source": [
        "##Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A77UsHyjwK89"
      },
      "source": [
        "\n",
        "#Import the pandas library\n",
        "#This library will be used to read in and organize the data.\n",
        "import pandas as pd\n",
        "\n",
        "#Import the train_test_split\n",
        "#This library will be used to create our training and test datasets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FQJqYoRbPN0"
      },
      "source": [
        "##Read in the Data Files\n",
        "###A brief description of the data being utilized.\n",
        "In this notebook we will be creating a XGBoost Model to analyze the Bach Chorales dataset.\n",
        "Chords are determined by the combination of notes being played. These notes are C, C#, D, D#, E, F, F#, G, G#, A, A#,B.There is also a bass note as well as a meter that determine the chord being played. This dataset has a variety of chords from Johann Sebastian Bach 1000 various pieces.\n",
        "The model will look to identify what chord is being played by analyzing the notes that are being played, the bass note and meter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfglqEjPbWt-",
        "outputId": "f43b3384-44aa-4635-aeb8-2d17b4934a65"
      },
      "source": [
        "#Use the wget command to import the model into the notebook's directory\n",
        "!wget https://raw.githubusercontent.com/zacharski/ml-class/master/data/bach.zip\n",
        "#Use the unzip command to unzip the file.\n",
        "!unzip bach.zip\n",
        "#Read in the csv file.\n",
        "bach = pd.read_csv('bach.csv')\n",
        "#View a sample of the dataset\n",
        "print(bach.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-16 18:32:38--  https://raw.githubusercontent.com/zacharski/ml-class/master/data/bach.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41761 (41K) [application/zip]\n",
            "Saving to: ‘bach.zip’\n",
            "\n",
            "\rbach.zip              0%[                    ]       0  --.-KB/s               \rbach.zip            100%[===================>]  40.78K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-10-16 18:32:39 (13.3 MB/s) - ‘bach.zip’ saved [41761/41761]\n",
            "\n",
            "Archive:  bach.zip\n",
            "  inflating: bach.csv                \n",
            "  choral_ID  event_number    C  C#   D  D#  ...    A  A#   B bass meter chord_label\n",
            "0  000106b_             1  YES  NO  NO  NO  ...  YES  NO  NO    F     3         F_M\n",
            "1  000106b_             2  YES  NO  NO  NO  ...   NO  NO  NO    E     5         C_M\n",
            "2  000106b_             3  YES  NO  NO  NO  ...   NO  NO  NO    E     2         C_M\n",
            "3  000106b_             4  YES  NO  NO  NO  ...  YES  NO  NO    F     3         F_M\n",
            "4  000106b_             5  YES  NO  NO  NO  ...  YES  NO  NO    F     2         F_M\n",
            "\n",
            "[5 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP3EJE-ekv0e"
      },
      "source": [
        "#Organize the Data\n",
        "##First we want to seperate the labels and the features.\n",
        "###We will be using the notes,bass, and meter for the features and the chord_label for the labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueSYaFiyldmC",
        "outputId": "97dc8f92-71f3-4dda-e9be-f9428c18dc5b"
      },
      "source": [
        "#Print all the columns \n",
        "print(bach.columns)\n",
        "#Determine which columns to drop to create the features.\n",
        "bach_features = bach.drop(columns=['choral_ID','event_number','chord_label'])\n",
        "#Create the label dataframe which consists of just the chord_label column.\n",
        "bach_labels = bach['chord_label']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['choral_ID', 'event_number', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G',\n",
            "       'G#', 'A', 'A#', 'B', 'bass', 'meter', 'chord_label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwQ8PfppmV3x"
      },
      "source": [
        "When looking at the note columns we can see that they are not numerically represented so these must be changed to have a 0 if the note is not being played and a 1 if it is being played. We also want to have a numerical representation of the bass column so the model can analyze this. This can be done by one_hot_encoding the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICqCKn_nTGS"
      },
      "source": [
        "#Replace YES, NO with 1,0 for the notes\n",
        "bach_features.replace(('YES','NO'),(1,0),inplace=True)\n",
        "#One hot encode the bass column\n",
        "bach_features = pd.get_dummies(bach_features)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThRI5XUw2bA6"
      },
      "source": [
        "#Split the data intro train and test data.\n",
        "bach_train_features,bach_test_features,bach_train_labels,bach_test_labels=train_test_split(bach_features,bach_labels,test_size = .4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCJtr3722LNP"
      },
      "source": [
        "#Build and Evaluate the Basic Model\n",
        "Next we will build a basic XGBoost Model without searching for the best parameters. The classifier will be a decision tree.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnEWiEWt-f5Y",
        "outputId": "872b7d61-f427-4656-8c86-7eccc526b728"
      },
      "source": [
        "#Create and fit the model.\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
        "bagging_clf = BaggingClassifier(clf, n_estimators=20, max_samples=100, \n",
        "                                bootstrap=True, n_jobs=-1)\n",
        "bagging_clf.fit(bach_train_features, bach_train_labels)\n",
        "predictions = bagging_clf.predict(bach_test_features)\n",
        "accuracy_score(bach_test_labels,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6672550750220653"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV7OLPSDBzcV"
      },
      "source": [
        "My accuracy for this base model was 66.7%, not bad! Let's see if we can do better though!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7lQgwtCCByF"
      },
      "source": [
        "#Finding the Ideal Parameters\n",
        "For our next step we want to figure out what the ideal parameters for our predictive model would be, the parameters we'll be adjusting are the n_estimators, bootstrap, and max_samples.\n",
        "\n",
        "The N_estimators parameter is used to represent the number of trees being used within the classifier.\n",
        "\n",
        "The bootstrap parameter can be summed up as a boolean value that represent replacement. True meaning the random training values will be replaced before drawing another one.\n",
        "\n",
        "The max_samples parameter represents the number of samples from the training data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4km9t-GMB_oj"
      },
      "source": [
        "#First create the param_grid that will contain the various values we would like to test\n",
        "hyperparam_grid = [\n",
        "    {'bootstrap': [True,False],'n_estimators':[80,100,120],'max_samples': [1200,1400,1600,1800]}\n",
        "  ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mOxi6a7V4X1"
      },
      "source": [
        "Next we want to utilize GridSearchCV to find the ideal parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inWdTCLkV4gH"
      },
      "source": [
        "grid_search = GridSearchCV(bagging_clf, hyperparam_grid, cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_oD27tPdA9d"
      },
      "source": [
        "Next we want to fit this model to find the best parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAi3Dg2bdEBB",
        "outputId": "b5819cbc-6bb7-492a-a760-89bc438b8a04"
      },
      "source": [
        "grid_search.fit(bach_train_features, bach_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                               class_weight=None,\n",
              "                                                                               criterion='entropy',\n",
              "                                                                               max_depth=None,\n",
              "                                                                               max_features=None,\n",
              "                                                                               max_leaf_nodes=None,\n",
              "                                                                               min_impurity_decrease=0.0,\n",
              "                                                                               min_impurity_split=None,\n",
              "                                                                               min_samples_leaf=1,\n",
              "                                                                               min_samples_split=2,\n",
              "                                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                                               presort='deprecated',\n",
              "                                                                               rando...\n",
              "                                         bootstrap_features=False,\n",
              "                                         max_features=1.0, max_samples=100,\n",
              "                                         n_estimators=20, n_jobs=-1,\n",
              "                                         oob_score=False, random_state=None,\n",
              "                                         verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'bootstrap': [True, False],\n",
              "                          'max_samples': [1200, 1400, 1600, 1800],\n",
              "                          'n_estimators': [80, 100, 120]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kBOpo-HdSkI",
        "outputId": "ca26d594-3869-4bff-a5e2-01807c142fc5"
      },
      "source": [
        "#Display the best parameters\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True, 'max_samples': 1400, 'n_estimators': 120}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMjA1MSo75c_"
      },
      "source": [
        "Here we can see the best parameters end up being bootstrap: True which means replacement of the samples taken. We will have 1400 samples taken. Finally 120 n_estimators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gts8qOPLdaDP"
      },
      "source": [
        "#Have the new model make the predicitions\n",
        "idealPredictions = grid_search.best_estimator_.predict(bach_test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh3iiZb6deEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ed133e-99a7-477a-a5a2-0cf473d62629"
      },
      "source": [
        "#Test the accuracy of the final model\n",
        "accuracy_score(bach_test_labels, idealPredictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7427184466019418"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fj3khoB8W95"
      },
      "source": [
        "We end up with a final accuracy of 74.3 so we see a total increase of 7.6% in our models accuracy just by doing a simple scan of some parameter combinations. There are of course a large multitude of hyper parameters we could test for to further increase the accuracy of our model!\n"
      ]
    }
  ]
}